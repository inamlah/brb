{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Bayesian analysis for fermionic rotational EFT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## I. K. Alnamlah, E. A. Coello PÃ©rez, D. R. Phillips"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing Libraries and Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import emcee\n",
    "import corner\n",
    "\n",
    "\n",
    "from levels import experiment_levels, Slope, E_r_LO_\n",
    "from plots import setup_rc_params\n",
    "setup_rc_params(fontsize=11)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining the error model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following block defines the theory estimate for the energy levels. This is at any order depending on the size of p, which tells the function how many LEC's it should use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def En(p,A,x,bandhead):\n",
    "    n=len(p)\n",
    "    E=p[0]+A*x*(x+1)\n",
    "    \n",
    "    if bandhead == '1/2':\n",
    "        for i,q in enumerate(p[2::2]):\n",
    "            if i ==0: E=E-A*x*(x+1)\n",
    "            E=E+q*(x*(x+1))**(i+1) \n",
    "                \n",
    "        for i,q in enumerate(p[1::2]):\n",
    "            E=E+q*(-1)**(x+1/2)*(x+1/2)*(x*(x+1))**i\n",
    "            \n",
    "    if bandhead == '3/2':\n",
    "        for i,q in enumerate(p[1::2]):\n",
    "            if i ==0: E=E-A*x*(x+1)\n",
    "            E=E+q*(x*(x+1))**(i+1) \n",
    "                \n",
    "        for i,q in enumerate(p[2::2]):\n",
    "            E=E+q*(-1)**(x+3/2)*(x-1/2)*(x+1/2)*(x+3/2)*(x*(x+1))**i\n",
    "            \n",
    "    if bandhead == '5/2':\n",
    "        for i,q in enumerate(p[1:]):\n",
    "            if i ==0: E=E-A*x*(x+1)\n",
    "            E=E+q*(x*(x+1))**(i+1) \n",
    "            \n",
    "    if bandhead == '7/2':\n",
    "        for i,q in enumerate(p[1:]):\n",
    "            if i ==0: E=E-A*x*(x+1)\n",
    "            E=E+q*(x*(x+1))**(i+1) \n",
    "\n",
    "    return E"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following block defines the theory error. `k+1` is the first term in the theory error `kmax` is the highest term. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def error_th(c_bar_odd,c_bar_even,y_ref,Q,x,k,kmax,bandhead):\n",
    "    error=[0*x*Q]\n",
    "    if bandhead == '1/2': s=1; structure=(x+1/2)\n",
    "    if bandhead == '3/2': s=3; structure=Q**2*(x-1/2)*(x+1/2)*(x+3/2)\n",
    "    if bandhead == '5/2': s=5; structure=Q**4*(x+5/2)*(x+3/2)*(x+1/2)*(x-1/2)*(x-3/2)\n",
    "    if bandhead == '7/2': s=7; structure=Q**6*(x+7/2)*(x+5/2)*(x+3/2)*(x+1/2)*(x-1/2)*(x-3/2)*(x-5/2)\n",
    "\n",
    "    for q in np.arange(k+1,kmax+1,1):\n",
    "\n",
    "        if q%2 ==0 :#if k is even\n",
    "            row=y_ref*c_bar_even*Q*x*(x+1)*(Q**2*(x*(x+1)))**((q-2)/2)\n",
    "            error.append(row)\n",
    "        \n",
    "        else:\n",
    "            if q >= s:\n",
    "                row=y_ref*c_bar_odd*structure*(-1)**(x+s/2)*(Q**2*(x*(x+1)))**((q-s)/2)\n",
    "                error.append(row)\n",
    "    return np.array(error[1:])    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following block has the log of the likelihood."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_likelihood(p,c_bar_odd,c_bar_even,Q,k,kmax,y_ref,I_odd,E_odd,error_odd_ex,verbose,bandhead):\n",
    "   \n",
    "    residual=E_odd-En(p,y_ref,I_odd,bandhead)\n",
    "    errorth=error_th(c_bar_odd,c_bar_even,y_ref,Q,I_odd,k,kmax,bandhead)\n",
    "    #print(np.array(errorth).shape)\n",
    "    sigma_th=errorth.T @ errorth\n",
    "    \n",
    "    sigma_ex=np.diag(error_odd_ex**2)\n",
    "    \n",
    "    C= sigma_th + sigma_ex\n",
    "\n",
    "    det=np.linalg.det(C)\n",
    "    \n",
    "    if det==0:\n",
    "        if verbose: print('singular');\n",
    "        return -np.inf\n",
    "    if det<0:\n",
    "        if verbose:\n",
    "            print('<0');\n",
    "            print('c_bar=',c_bar_odd);\n",
    "            print('Q=',Q);\n",
    "            print('det=',det)\n",
    "\n",
    "    prefactor=(2*np.pi)**(-len(I_odd)/2)*det**(-1/2)\n",
    "    \n",
    "    log_likelihood=np.log(prefactor)-1/2*residual.T @ np.linalg.inv(C) @ residual\n",
    "    \n",
    "    return log_likelihood"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining the priors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_prior_on_LECs(p,c_bar_odd,c_bar_even,Q,sigma_E,y_ref,bandhead):\n",
    "    sigma=sigma_E\n",
    "    prefactor=np.log(1/(sigma*np.sqrt(2*np.pi)))\n",
    "    log_prior=prefactor-1/2*p[0]**2/sigma**2\n",
    "    \n",
    "    for i,q in enumerate(p[1:]):\n",
    "        if bandhead == '3/2': i=i+1\n",
    "        if bandhead == '5/2': i=i*2+1\n",
    "        if bandhead == '7/2': i=i*2+1\n",
    "            \n",
    "        if i%2 ==0: c=np.sqrt(c_bar_odd**2);\n",
    "        else: c=np.sqrt(c_bar_even**2)\n",
    "            \n",
    "        sigma=c*y_ref*Q**i\n",
    "        prefactor=np.log(1/(sigma*np.sqrt(2*np.pi)))\n",
    "        \n",
    "        if i ==1: q=q-y_ref\n",
    "            \n",
    "        log_prior=log_prior+prefactor-1/2*q**2/sigma**2\n",
    "    return log_prior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.special import gamma\n",
    "def f_inverse_chi_squared(z, nu, tau):\n",
    "    \"\"\"\n",
    "    Density for the scaled inverse chi^2 distribution\n",
    "    Mode should be nu tau^2 / (nu + 2) and mean nu tau^2 / (nu - 2) for n > 2\n",
    "    \"\"\"\n",
    "    prefactor = (nu * tau**2 / 2)**(nu/2) / gamma(nu/2)\n",
    "    return prefactor / z**(1 + nu/2) * np.exp(-nu * tau**2 / (2 * z))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.9992021155721773, 5.910356001139788e-10)\n"
     ]
    }
   ],
   "source": [
    "import scipy.integrate as integrate\n",
    "import scipy.special as special\n",
    "\n",
    "result = integrate.quad(lambda x:f_inverse_chi_squared(x**2, 1, 1)*2*x, 0, 1000)\n",
    "\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building the posterior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_posterior(q,n_om,y_ref,I_odd,E_odd,error_odd_ex,sigma_E,Q_cutoff,c_bar_cutoff_odd,c_bar_cutoff_even,bandhead,verbose=True):\n",
    "    \n",
    "    p=q[:-3]\n",
    "    Q=q[-3]\n",
    "    c_bar_even=q[-2]\n",
    "    c_bar_odd=q[-1]\n",
    "    \n",
    "    if Q<=0: return -np.inf\n",
    "    if Q>Q_cutoff: return -np.inf\n",
    "    if c_bar_even<=0: return -np.inf\n",
    "    if c_bar_odd<=0: return -np.inf\n",
    "    if c_bar_odd>c_bar_cutoff_odd: return -np.inf\n",
    "    if c_bar_even>c_bar_cutoff_even: return -np.inf\n",
    "    \n",
    "    if bandhead == '1/2': k=len(p)-1\n",
    "    if bandhead == '3/2': k=len(p)\n",
    "    if bandhead == '5/2': k=len(p)*2-2\n",
    "    if bandhead == '7/2': k=len(p)*2-2\n",
    "    kmax=k+n_om\n",
    "    \n",
    "    log_likelihood1=log_likelihood(p,c_bar_odd,c_bar_even,Q,k,kmax,y_ref,I_odd,E_odd,error_odd_ex,verbose,bandhead)\n",
    "    log_prior_on_LECs1=log_prior_on_LECs(p,c_bar_odd,c_bar_even,Q,sigma_E,y_ref,bandhead)\n",
    "    log_prior_on_Q=0\n",
    "    log_prior_on_c_bar_odd=np.log(f_inverse_chi_squared(c_bar_odd**2, 1,1))+np.log(2*c_bar_odd)\n",
    "    log_prior_on_c_bar_even=np.log(f_inverse_chi_squared(c_bar_even**2, 1,1))+np.log(2*c_bar_even)\n",
    "    \n",
    "    log_posterior= log_likelihood1+log_prior_on_LECs1+log_prior_on_Q+log_prior_on_c_bar_odd+log_prior_on_c_bar_even\n",
    "    return log_posterior\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sampling the Posterior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample(nwalkers,n_steps,range_of_starting_guesses,sigma_E,nLECs,nomitted,A,I_odd,E_odd,error_odd_ex,Q_cutoff,c_bar_cutoff_odd,c_bar_cutoff_even,bandhead,plots=True):\n",
    "\n",
    "\n",
    "    ndim=nLECs+3 # No. of dimension in parameter space or No. of parametres\n",
    "    range_of_starting_guesses=range_of_starting_guesses[:nLECs]+range_of_starting_guesses[-3:]\n",
    "    starting_guesses = range_of_starting_guesses + (2.0*np.random.rand(nwalkers,ndim)-1.0)*1e-3\n",
    "    \n",
    "    sampler = emcee.EnsembleSampler(nwalkers, ndim, log_posterior, args=[nomitted,A,I_odd,E_odd,error_odd_ex,sigma_E,Q_cutoff,c_bar_cutoff_odd,c_bar_cutoff_even,bandhead])\n",
    "    old_tau = np.inf\n",
    "    sampler.run_mcmc(starting_guesses, 10000,progress=True)\n",
    "\n",
    "    # Compute the autocorrelation time so far\n",
    "    # Using tol=0 means that we'll always get an estimate even\n",
    "    # if it isn't trustworthy\n",
    "    tau = sampler.get_autocorr_time(tol=0)\n",
    "\n",
    "    # Check convergence\n",
    "    print(tau * 50 ,np.mean(tau)*50, sampler.iteration)\n",
    "    print(np.abs(old_tau - tau) / tau)\n",
    "    converged = np.all(tau * 50 < sampler.iteration)\n",
    "    converged &= np.all(np.abs(old_tau - tau) / tau < 0.01)\n",
    "    \n",
    "    while  converged == False and sampler.iteration<80000:\n",
    "        old_tau = tau\n",
    "        sampler.run_mcmc(initial_state= None,nsteps= 3000,progress=True)\n",
    "        tau = sampler.get_autocorr_time(tol=0)\n",
    "        print(tau * 50 ,np.mean(tau)*50, sampler.iteration)\n",
    "        print(np.abs(old_tau - tau) / tau)\n",
    "        converged = np.all(tau * 50 < sampler.iteration)\n",
    "        converged &= np.all(np.abs(old_tau - tau) / tau < 0.02)\n",
    "        \n",
    "    \n",
    "    tau = sampler.get_autocorr_time(tol=0)\n",
    "    burnin = int(2 * np.max(tau))\n",
    "    thin = int(0.5 * np.min(tau))\n",
    "    flat_samples = sampler.get_chain(discard=burnin, flat=True, thin=thin)\n",
    "\n",
    "    print(\"burn-in: {0}\".format(burnin))\n",
    "    print(\"thin: {0}\".format(thin))\n",
    "    print(\"flat chain shape: {0}\".format(flat_samples.shape))\n",
    "\n",
    "    samples = sampler.get_chain()\n",
    "    if plots:\n",
    "        if bandhead == '1/2':\n",
    "            labels=[r'$E_K$',r'$A_1$',r'$A$',r'$B_1$',r'$B$',r'$Q$',r'$\\bar{c}_{\\rm even}$',r'$\\bar{c}_{\\rm odd}$']\n",
    "        elif bandhead == '3/2':\n",
    "            labels=[r'$E_K$',r'$A$',r'$A_3$',r'$B$',r'$Q$',r'$\\bar{c}_{\\rm even}$',r'$\\bar{c}_{\\rm odd}$']\n",
    "        elif bandhead == '5/2':\n",
    "            labels=[r'$E_K$',r'$A$',r'$B$',r'$Q$',r'$\\bar{c}_{\\rm even}$',r'$\\bar{c}_{\\rm odd}$']\n",
    "        elif bandhead == '7/2':\n",
    "            labels=[r'$E_K$',r'$A$',r'$B$',r'$Q$',r'$\\bar{c}_{\\rm even}$',r'$\\bar{c}_{\\rm odd}$']\n",
    "        labels=labels[:nLECs]+labels[-3:]\n",
    "\n",
    "        fig1, axes = plt.subplots(ndim, figsize=(10, 7), sharex=True)\n",
    "        for i in range(ndim):\n",
    "            ax = axes[i]\n",
    "            ax.plot(samples[:, :, i], \"k\", alpha=0.1)\n",
    "            ax.set_ylabel(labels[i])\n",
    "\n",
    "        axes[-1].set_xlabel(\"step number\",fontsize=20);\n",
    "        plt.show()\n",
    "        plt.close()\n",
    "        setup_rc_params(fontsize=16)\n",
    "        fig2 = corner.corner(flat_samples,labels=labels, show_titles=True,use_math_text=True,verbose=True,max_n_ticks=3,\n",
    "             label_kwargs={'fontsize':18,'rotation':0},title_fmt='.4f',title_kwargs={'fontsize':14},\n",
    "             quantiles=[],reverse=False,labelpad=0.2,top_ticks=False,fontsize=18);\n",
    "        plt.show()\n",
    "        plt.close()\n",
    "        setup_rc_params(fontsize=11)\n",
    "        return samples,tau,fig1,fig2\n",
    "    else:\n",
    "        return samples,tau\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nuclei_parm(odd):\n",
    "    nla=0\n",
    "    nlb=0\n",
    "    if odd == r'$^{169}$Er': rotor=r'$^{168}$Er';m=0;bandhead='1/2';\\\n",
    "        sigma_E,Q_cutoff,c_bar_cutoff_odd,c_bar_cutoff_even=22,0.16,22,22;\\\n",
    "        range_of_starting_guesses=[0.0,10,12,-0.007,-0.004,0.05,2,1]  # set the cuttoffs on the hyperparameters\n",
    "        \n",
    "    if odd == r'$^{167}$Er': rotor=r'$^{166}$Er';m=1;bandhead='1/2';\\\n",
    "        sigma_E,Q_cutoff,c_bar_cutoff_odd,c_bar_cutoff_even=230,0.08,8,16; \\\n",
    "        range_of_starting_guesses=[0.0,8,11,-0.005,-0.008,0.05,2,1]  # set the cuttoffs on the hyperparameters\n",
    "    if odd == r'$^{167}$Er_3/2': rotor=r'$^{166}$Er';m=13;bandhead='3/2';\\\n",
    "        sigma_E,Q_cutoff,c_bar_cutoff_odd,c_bar_cutoff_even=573,0.2,22,22; \\\n",
    "        range_of_starting_guesses=[0.0,11,-0.005,-0.008,0.05,2,1]  # set the cuttoffs on the hyperparameters\n",
    "    if odd == r'$^{167}$Er_5/2': rotor=r'$^{166}$Er';m=14;bandhead='5/2';\\\n",
    "        sigma_E,Q_cutoff,c_bar_cutoff_odd,c_bar_cutoff_even=445,0.2,22,22; \\\n",
    "        range_of_starting_guesses=[0.0,11,-0.008,0.05,2,1]  # set the cuttoffs on the hyperparameters\n",
    "    if odd == r'$^{167}$Er_7/2': rotor=r'$^{166}$Er';m=15;bandhead='7/2';\\\n",
    "        sigma_E,Q_cutoff,c_bar_cutoff_odd,c_bar_cutoff_even=174,0.2,22,22; \\\n",
    "        range_of_starting_guesses=[0.0,11,-0.008,0.05,2,1]  # set the cuttoffs on the hyperparameters\n",
    "\n",
    "    if odd == r'$^{169}$Tm': rotor=r'$^{168}$Er';m=2;bandhead='1/2';\\\n",
    "        sigma_E,Q_cutoff,c_bar_cutoff_odd,c_bar_cutoff_even=22,0.16,22,22; \\\n",
    "        range_of_starting_guesses=[0.0,-10,12,0.03,-0.005,0.05,2,1]  # set the cuttoffs on the hyperparameters\n",
    "    if odd == r'$^{167}$Tm': rotor=r'$^{166}$Er';m=3;bandhead='1/2';\\\n",
    "        sigma_E,Q_cutoff,c_bar_cutoff_odd,c_bar_cutoff_even=22,0.16,22,22;\\\n",
    "        range_of_starting_guesses=[0.0,-9,12,0.04,-0.008,0.05,2,1]  # set the cuttoffs on the hyperparameters\n",
    "    if odd == r'$^{99}$Tc': rotor=r'$^{100}$Ru';m=4;nla=5;bandhead='1/2';\\\n",
    "        sigma_E,Q_cutoff,c_bar_cutoff_odd,c_bar_cutoff_even=160,0.3,2.5,2.5;\\\n",
    "        range_of_starting_guesses=[0.0,60,80,-3,-1,0.2,2,1]  # set the cuttoffs on the hyperparameters\n",
    "    if odd == r'$^{183}$W': rotor=r'$^{182}$W';m=5;nla=2;bandhead='1/2';\\\n",
    "        sigma_E,Q_cutoff,c_bar_cutoff_odd,c_bar_cutoff_even=22,0.12,15,22;\\\n",
    "        range_of_starting_guesses=[0.0,3,13,-0.03,0.013,0.05,2,1]  # set the cuttoffs on the hyperparameters\n",
    "        \n",
    "    if odd == r'$^{235}$U': rotor=r'$^{234}$U';m=6;bandhead='1/2';\\\n",
    "        sigma_E,Q_cutoff,c_bar_cutoff_odd,c_bar_cutoff_even=22,0.1,40,40;\\\n",
    "        range_of_starting_guesses=[0.0,-2,6,0.002,-0.003,0.05,2,1]  # set the cuttoffs on the hyperparameters\n",
    "    if odd == r'$^{235}$U_5/2': rotor=r'$^{234}$U';m=16;bandhead='5/2';\\\n",
    "        sigma_E,Q_cutoff,c_bar_cutoff_odd,c_bar_cutoff_even=180,0.15,22,22;\\\n",
    "        range_of_starting_guesses=[0.0,6,-0.003,0.05,2,1]  # set the cuttoffs on the hyperparameters\n",
    "    if odd == r'$^{235}$U_7/2': rotor=r'$^{234}$U';m=17;bandhead='7/2';\\\n",
    "        sigma_E,Q_cutoff,c_bar_cutoff_odd,c_bar_cutoff_even=100,0.1,22,22;\\\n",
    "        range_of_starting_guesses=[0.0,6,-0.003,0.05,2,1]  # set the cuttoffs on the hyperparameters\n",
    "\n",
    "\n",
    "\n",
    "    if odd == r'$^{239}$Pu': rotor=r'$^{238}$Pu';m=7;bandhead='1/2';\\\n",
    "        sigma_E,Q_cutoff,c_bar_cutoff_odd,c_bar_cutoff_even=22,0.075,4.5,40 ;\\\n",
    "        range_of_starting_guesses=[0.0,-4,6,0.004,-0.002,0.05,2,1]  # set the cuttoffs on the hyperparameters\n",
    "    if odd == r'$^{159}$Dy': rotor=r'$^{158}$Dy';m=8;bandhead='3/2';nla=12;\\\n",
    "        sigma_E,Q_cutoff,c_bar_cutoff_odd,c_bar_cutoff_even=61.8125,0.09,10,20;\\\n",
    "        range_of_starting_guesses=[0.0,11,-0.005,-0.005,0.05,2,1]  # set the cuttoffs on the hyperparameters\n",
    "    if odd == r'$^{159}$Gd': rotor=r'$^{158}$Gd';m=9;bandhead='3/2';\\\n",
    "        sigma_E,Q_cutoff,c_bar_cutoff_odd,c_bar_cutoff_even=50,0.12,10,20;\\\n",
    "        range_of_starting_guesses=[0.0,12,-0.01,-0.005,0.05,2,1]  # set the cuttoffs on the hyperparameters\n",
    "    if odd == r'$^{157}$Gd': rotor=r'$^{156}$Gd';m=10;bandhead='3/2';\\\n",
    "        sigma_E,Q_cutoff,c_bar_cutoff_odd,c_bar_cutoff_even=55.625,0.12,10,20;\\\n",
    "        range_of_starting_guesses=[0.0,12,-0.01,-0.005,0.05,2,1]  # set the cuttoffs on the hyperparameters\n",
    "    if odd == r'$^{155}$Gd': rotor=r'$^{154}$Gd';m=11;bandhead='3/2';\\\n",
    "        sigma_E,Q_cutoff,c_bar_cutoff_odd,c_bar_cutoff_even=76.9375,0.12,10,20;\\\n",
    "        range_of_starting_guesses=[0.0,12,-0.01,-0.005,0.05,2,1]  # set the cuttoffs on the hyperparameters\n",
    "    if odd == r'$^{153}$Gd': rotor=r'$^{152}$Gd';m=12;bandhead='3/2';\\\n",
    "        sigma_E,Q_cutoff,c_bar_cutoff_odd,c_bar_cutoff_even=50,0.12,10,20;\\\n",
    "        range_of_starting_guesses=[0.0,12,-0.01,-0.005,0.05,2,1]   #set the cuttoffs on the hyperparameters\n",
    "    if bandhead == '1/2':\n",
    "        labels=[r'$E_K$',r'$A_1$',r'$A$',r'$B_1$',r'$B$',r'$Q$',r'$\\bar{c}_{\\rm even}$',r'$\\bar{c}_{\\rm odd}$']\n",
    "    elif bandhead == '3/2':\n",
    "        labels=[r'$E_K$',r'$A$',r'$A_3$',r'$B$',r'$Q$',r'$\\bar{c}_{\\rm even}$',r'$\\bar{c}_{\\rm odd}$']\n",
    "    elif bandhead == '5/2':\n",
    "        labels=[r'$E_K$',r'$A$',r'$B$',r'$Q$',r'$\\bar{c}_{\\rm even}$',r'$\\bar{c}_{\\rm odd}$']\n",
    "    elif bandhead == '7/2':\n",
    "        labels=[r'$E_K$',r'$A$',r'$B$',r'$Q$',r'$\\bar{c}_{\\rm even}$',r'$\\bar{c}_{\\rm odd}$']\n",
    "\n",
    "    return rotor,bandhead,sigma_E,Q_cutoff,c_bar_cutoff_odd,c_bar_cutoff_even,range_of_starting_guesses,m,nla,nlb,labels\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nwalkers,n_steps=64,100000\n",
    "\n",
    "odd=r'$^{167}$Er' # choose the odd nucleus\n",
    "nLECs=5                 # choose the number of LEC's (This determines what order you want to calculate in your EFT)\n",
    "nomitted=6              # and the number of omitted error terms\n",
    "\n",
    "rotor,bandhead,sigma_E,Q_cutoff,c_bar_cutoff_odd,c_bar_cutoff_even,range_of_starting_guesses,m,nla,nlb,labels=nuclei_parm(odd)\n",
    "E_rot,E_vib,E_sp,E_r,error_r_ex,I_r,E_odd,error_odd_ex,I_odd=experiment_levels(rotor,odd)\n",
    "n=len(I_odd)\n",
    "E_odd,error_odd_ex,I_odd=E_odd[nlb:n-nla],error_odd_ex[nlb:n-nla],I_odd[nlb:n-nla]\n",
    "A,A_r_NLO,B_r_NLO,E_r=E_r_LO_(E_r,I_r)\n",
    "\n",
    "print('for ',odd,'N'+str(nLECs-1)+'LO')\n",
    "print('number of error terms is ',nomitted)\n",
    "print('number of levels is ',n-nla-nlb)\n",
    "print('number of removed levels from above is ',nla)\n",
    "print('number of removed levels from below is ',nlb)\n",
    "\n",
    "samples,autocorrelation,fig1,fig2=sample(nwalkers,n_steps,range_of_starting_guesses,sigma_E,nLECs,nomitted,A,I_odd,E_odd,error_odd_ex,Q_cutoff,c_bar_cutoff_odd,c_bar_cutoff_even,bandhead,plots=True)\n",
    "#np.save(    'samples_'+odd+'_N'+str(nLECs-1)+'LO_error_'+str(nomitted)+'_levles_'+str(nlb)+'_'+str(n-nla)+str(Q_cutoff),[samples,autocorrelation])\n",
    "#fig1.savefig('chains_'+odd+'_N'+str(nLECs-1)+'LO_error_'+str(nomitted)+'_levles_'+str(nlb)+'_'+str(n-nla)+str(Q_cutoff)+'.png')\n",
    "#fig2.savefig('corner_'+odd+'_N'+str(nLECs-1)+'LO_error_'+str(nomitted)+'_levles_'+str(nlb)+'_'+str(n-nla)+str(Q_cutoff)+'.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nwalkers,n_steps=64,100000\n",
    "nuclei=[r'$^{169}$Er',r'$^{167}$Er',r'$^{169}$Tm',r'$^{167}$Tm',r'$^{235}$U',r'$^{239}$Pu',r'$^{183}$W',r'$^{99}$Tc',r'$^{159}$Dy',r'$^{157}$Gd',r'$^{155}$Gd']\n",
    " \n",
    "\n",
    "for odd in nuclei: # choose the odd nucleus\n",
    "    k=4 \n",
    "    kmax=10\n",
    "    \n",
    "    rotor,bandhead,sigma_E,Q_cutoff,c_bar_cutoff_odd,c_bar_cutoff_even,range_of_starting_guesses,m,nla,nlb,labels=nuclei_parm(odd)\n",
    "    E_rot,E_vib,E_sp,E_r,error_r_ex,I_r,E_odd,error_odd_ex,I_odd=experiment_levels(rotor,odd)\n",
    "    n=len(I_odd)\n",
    "    E_odd,error_odd_ex,I_odd=E_odd[nlb:n-nla],error_odd_ex[nlb:n-nla],I_odd[nlb:n-nla]\n",
    "    A,A_r_NLO,B_r_NLO,E_r=E_r_LO_(E_r,I_r)\n",
    "    \n",
    "    if bandhead =='1/2': nLECs=k+1\n",
    "    if bandhead =='3/2': nLECs=k\n",
    "    if odd ==r'$^{159}$Dy':kmax=12\n",
    "    nomitted=kmax-k\n",
    "    \n",
    "    print('for ',odd,r'N$^%1i$'%k+'LO')\n",
    "    print('number of error terms is ',nomitted)\n",
    "    print('number of levels is ',n-nla-nlb)\n",
    "    print('number of removed levels from above is ',nla)\n",
    "    print('number of removed levels from below is ',nlb)\n",
    "\n",
    "    samples,autocorrelation,fig1,fig2=sample(nwalkers,n_steps,range_of_starting_guesses,sigma_E,nLECs,nomitted,A,I_odd,E_odd,error_odd_ex,Q_cutoff,c_bar_cutoff_odd,c_bar_cutoff_even,bandhead,plots=True)\n",
    "    np.save(    'samples_'+odd+'_N'+str(k)+'LO_error_'+str(nomitted)+'_levles_'+str(nlb)+'_'+str(n-nla),[samples,autocorrelation])\n",
    "    fig1.savefig('chains_'+odd+'_N'+str(k)+'LO_error_'+str(nomitted)+'_levles_'+str(nlb)+'_'+str(n-nla)+'.png')\n",
    "    fig2.savefig('corner_'+odd+'_N'+str(k)+'LO_error_'+str(nomitted)+'_levles_'+str(nlb)+'_'+str(n-nla)+'.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Removing Levels from above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "nuclei=[r'$^{169}$Er']\n",
    "\n",
    "nwalkers,n_steps=64,16500 # set the sampler parameters\n",
    "kmax=10\n",
    "\n",
    "for nLECs in range(2,6,1):\n",
    "    k=nLECs-1\n",
    "    nomitted=kmax-k\n",
    "    \n",
    "    \n",
    "    for odd in  nuclei:\n",
    "\n",
    "        rotor,bandhead,sigma_E,Q_cutoff,c_bar_cutoff_odd,c_bar_cutoff_even,range_of_starting_guesses,m,nla,nlb,labels=nuclei_parm(odd)\n",
    "        E_rot,E_vib,E_sp,E_r,error_r_ex,I_r,E_odd,error_odd_ex,I_odd=experiment_levels(rotor,odd)\n",
    "        A,A_r_NLO,B_r_NLO,E_r=E_r_LO_(E_r,I_r)\n",
    "        n=len(I_odd)\n",
    "\n",
    "        for nla1 in range(nla,n-4,1):\n",
    "\n",
    "            E_odd,error_odd_ex,I_odd=E_odd[nlb:n-nla1],error_odd_ex[nlb:n-nla1],I_odd[nlb:n-nla1]\n",
    "            \n",
    "   \n",
    "    \n",
    "            print('for ',odd,r'N$^%1i$'%k+'LO')\n",
    "            print('number of error terms is ',nomitted)\n",
    "            print('number of levels is ',n-nla1-nlb)\n",
    "            print('number of removed levels from above is ',nla1)\n",
    "            print('number of removed levels from below is ',nlb)\n",
    "\n",
    "            samples,autocorrelation,fig1,fig2=sample(nwalkers,n_steps,range_of_starting_guesses,sigma_E,nLECs,nomitted,A,I_odd,E_odd,error_odd_ex,Q_cutoff,c_bar_cutoff_odd,c_bar_cutoff_even,bandhead,plots=True)\n",
    "            np.save(    'samples/samples_'+odd+'_N'+str(k)+'LO_error_'+str(nomitted)+'_levles_'+str(nlb)+'_'+str(n-nla1),[samples,autocorrelation])\n",
    "            fig1.savefig('samples/chains_'+odd+'_N'+str(k)+'LO_error_'+str(nomitted)+'_levles_'+str(nlb)+'_'+str(n-nla1)+'.png')\n",
    "            fig2.savefig('samples/corner_'+odd+'_N'+str(k)+'LO_error_'+str(nomitted)+'_levles_'+str(nlb)+'_'+str(n-nla1)+'.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "nuclei=[r'$^{239}$Pu']\n",
    "\n",
    "nwalkers,n_steps=64,16500 # set the sampler parameters\n",
    "\n",
    "for nLECs in range(5,6,1):\n",
    "    k=nLECs-1\n",
    "    for kmax in [6,8,10]:\n",
    "        nomitted=kmax-k\n",
    "        \n",
    "        for odd in  nuclei:\n",
    "\n",
    "            rotor,bandhead,sigma_E,Q_cutoff,c_bar_cutoff_odd,c_bar_cutoff_even,range_of_starting_guesses,m,nla,nlb,labels=nuclei_parm(odd)\n",
    "            E_rot,E_vib,E_sp,E_r,error_r_ex,I_r,E_odd,error_odd_ex,I_odd=experiment_levels(rotor,odd)\n",
    "            A,A_r_NLO,B_r_NLO,E_r=E_r_LO_(E_r,I_r)\n",
    "            n=len(I_odd)\n",
    "\n",
    "            for nla1 in range(nla,n-4,1):\n",
    "\n",
    "                E_odd,error_odd_ex,I_odd=E_odd[nlb:n-nla1],error_odd_ex[nlb:n-nla1],I_odd[nlb:n-nla1]\n",
    "\n",
    "\n",
    "\n",
    "                print('for ',odd,r'N$^%1i$'%k+'LO')\n",
    "                print('number of error terms is ',nomitted)\n",
    "                print('number of levels is ',n-nla1-nlb)\n",
    "                print('number of removed levels from above is ',nla1)\n",
    "                print('number of removed levels from below is ',nlb)\n",
    "\n",
    "                samples,autocorrelation,fig1,fig2=sample(nwalkers,n_steps,range_of_starting_guesses,sigma_E,nLECs,nomitted,A,I_odd,E_odd,error_odd_ex,Q_cutoff,c_bar_cutoff_odd,c_bar_cutoff_even,bandhead,plots=True)\n",
    "                np.save(    'samples/samples_'+odd+'_N'+str(k)+'LO_error_'+str(nomitted)+'_levles_'+str(nlb)+'_'+str(n-nla1),[samples,autocorrelation])\n",
    "                fig1.savefig('samples/chains_'+odd+'_N'+str(k)+'LO_error_'+str(nomitted)+'_levles_'+str(nlb)+'_'+str(n-nla1)+'.png')\n",
    "                fig2.savefig('samples/corner_'+odd+'_N'+str(k)+'LO_error_'+str(nomitted)+'_levles_'+str(nlb)+'_'+str(n-nla1)+'.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Removing Levels from below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nuclei=[r'$^{169}$Er']\n",
    "\n",
    "\n",
    "nwalkers,n_steps=64,21500 # set the sampler parameters\n",
    "for nLECs in [5]:\n",
    "    k=nLECs-1\n",
    "    for kmax in [10]:\n",
    "        nomitted=kmax-k\n",
    "        for odd in  nuclei:\n",
    "            \n",
    "            rotor,bandhead,sigma_E,Q_cutoff,c_bar_cutoff_odd,c_bar_cutoff_even,range_of_starting_guesses,m,nla,nlb,labels=nuclei_parm(odd)\n",
    "            E_rot,E_vib,E_sp,E_r,error_r_ex,I_r,E_odd,error_odd_ex,I_odd=experiment_levels(rotor,odd)\n",
    "            A,A_r_NLO,B_r_NLO,E_r=E_r_LO_(E_r,I_r)\n",
    "            n=len(I_odd)\n",
    "\n",
    "            for nlb in range(1,n-nla-4,1):\n",
    "\n",
    "                E_odd,error_odd_ex,I_odd=E_odd[nlb:n-nla],error_odd_ex[nlb:n-nla],I_odd[nlb:n-nla]\n",
    "    \n",
    "                print('for ',odd,r'N$^%1i$'%k+'LO')\n",
    "                print('number of error terms is ',nomitted)\n",
    "                print('number of levels is ',n-nla-nlb)\n",
    "                print('number of removed levels from above is ',nla)\n",
    "                print('number of removed levels from below is ',nlb)\n",
    "\n",
    "                samples,autocorrelation,fig1,fig2=sample(nwalkers,n_steps,range_of_starting_guesses,sigma_E,nLECs,nomitted,A,I_odd,E_odd,error_odd_ex,Q_cutoff,c_bar_cutoff_odd,c_bar_cutoff_even,bandhead,plots=True)\n",
    "                np.save(    'samples/samples_'+odd+'_N'+str(k)+'LO_error_'+str(nomitted)+'_levles_'+str(nlb)+'_'+str(n-nla),[samples,autocorrelation])\n",
    "                fig1.savefig('samples/chains_'+odd+'_N'+str(k)+'LO_error_'+str(nomitted)+'_levles_'+str(nlb)+'_'+str(n-nla)+'.png')\n",
    "                fig2.savefig('samples/corner_'+odd+'_N'+str(k)+'LO_error_'+str(nomitted)+'_levles_'+str(nlb)+'_'+str(n-nla)+'.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nuclei=[r'$^{169}$Er',r'$^{167}$Er',r'$^{169}$Tm',r'$^{167}$Tm',r'$^{235}$U',r'$^{239}$Pu',r'$^{183}$W',r'$^{99}$Tc',r'$^{159}$Dy',r'$^{157}$Gd',r'$^{155}$Gd']\n",
    "\n",
    "\n",
    "for odd in nuclei:\n",
    "    \n",
    "    rotor,bandhead,sigma_E,Q_cutoff,c_bar_cutoff_odd,c_bar_cutoff_even,range_of_starting_guesses,m,nla,nlb,labels=nuclei_parm(odd)\n",
    "    E_rot,E_vib,E_sp,E_r,error_r_ex,I_r,E_odd,error_odd_ex,I_odd=experiment_levels(rotor,odd)\n",
    "    n=len(I_odd)\n",
    "        \n",
    "    for nLECs in range(5,6,1):\n",
    "        \n",
    "        for nomitted in [6]:\n",
    "            \n",
    "            if odd == r'$^{159}$Dy': nomitted=8; nla=12\n",
    "            samples,autocorrelation=np.load('samples/samples_'+odd+'_N'+str(nLECs-1)+'LO_error_'+str(nomitted)+'_levles_'+str(nlb)+'_'+str(n-nla)+'.npy',allow_pickle=True)\n",
    "            tau = autocorrelation\n",
    "            burnin = int(2 * np.max(tau))\n",
    "            thin = int(0.5 * np.min(tau))\n",
    "\n",
    "            flat_samples=samples[burnin::thin, :, :]\n",
    "            flat_samples = [item for sublist in flat_samples for item in sublist]\n",
    "\n",
    "            np.save('parameters for plots/flat_samples_'+odd+'_N'+str(nLECs-1)+'LO_error_'+str(nomitted)+'_levles_'+str(nlb)+'_'+str(n-nla)+'.npy',flat_samples,allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nuclei=[r'$^{169}$Er',r'$^{167}$Er',r'$^{169}$Tm',r'$^{167}$Tm',r'$^{235}$U',r'$^{239}$Pu',r'$^{183}$W',r'$^{99}$Tc',r'$^{159}$Dy',r'$^{157}$Gd',r'$^{155}$Gd']\n",
    "\n",
    "\n",
    "for odd in nuclei:\n",
    "\n",
    "    ll=5\n",
    "\n",
    "    for LEC in [0,1,2,3,4,-3,-2,-1]:\n",
    "        print(LEC)\n",
    "\n",
    "        if LEC >1: s=LEC+1\n",
    "        else: s=2\n",
    "\n",
    "        for nLECs in range(s,6,1):\n",
    "\n",
    "\n",
    "            rotor,bandhead,sigma_E,Q_cutoff,c_bar_cutoff_odd,c_bar_cutoff_even,range_of_starting_guesses,m,nla,nlb,labels=nuclei_parm(odd)\n",
    "            E_rot,E_vib,E_sp,E_r,error_r_ex,I_r,E_odd,error_odd_ex,I_odd=experiment_levels(rotor,odd)\n",
    "            A,A_r_NLO,B_r_NLO,E_r=E_r_LO_(E_r,I_r)\n",
    "\n",
    "            n=len(I_odd)\n",
    "            for nomitted in [4]:\n",
    "                y11=[]\n",
    "                for nla1 in range(nla,n-ll,1):\n",
    "                    E_odd,error_odd_ex,I_odd=E_odd[nlb:n-nla1],error_odd_ex[nlb:n-nla1],I_odd[nlb:n-nla1]\n",
    "\n",
    "                    samples,autocorrelation=np.load('samples_'+odd+'_N'+str(nLECs-1)+'LO_error_'+str(nomitted)+'_levles_'+str(nlb)+'_'+str(n-nla1)+'.npy',allow_pickle=True)\n",
    "                    tau = autocorrelation\n",
    "                    burnin = int(2 * np.max(tau))\n",
    "                    thin = int(0.5 * np.min(tau))\n",
    "\n",
    "                    flat_samples=samples[burnin::thin, :, :]\n",
    "                    flat_samples = [item for sublist in flat_samples for item in sublist]\n",
    "                    z=np.array(flat_samples).T\n",
    "\n",
    "                    y=z[LEC]\n",
    "                    mcmc = np.percentile(y, [16, 50, 84])\n",
    "                    y1= np.array([mcmc[1],np.diff(mcmc)[0],np.diff(mcmc)[1]])\n",
    "                    y11.append((y1))\n",
    "\n",
    "                np.save(str(labels[LEC])+'_'+odd+'_N'+str(nLECs-1)+'LO_error_'+str(nomitted)+'_levles_'+str(nlb)+'_'+str(n-nla),y11)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nuclei=[r'$^{169}$Er',r'$^{167}$Er',r'$^{169}$Tm',r'$^{167}$Tm',r'$^{235}$U',r'$^{239}$Pu',r'$^{183}$W',r'$^{99}$Tc',r'$^{159}$Dy',r'$^{157}$Gd',r'$^{155}$Gd']\n",
    "\n",
    "ll=5\n",
    "LEC=2\n",
    "kmax=8\n",
    "odd=nuclei[5]\n",
    "nLECs=5\n",
    "rotor,bandhead,sigma_E,Q_cutoff,c_bar_cutoff_odd,c_bar_cutoff_even,range_of_starting_guesses,m,nla,nlb,labels=nuclei_parm(odd)\n",
    "E_rot,E_vib,E_sp,E_r,error_r_ex,I_r,E_odd,error_odd_ex,I_odd=experiment_levels(rotor,odd)\n",
    "A,A_r_NLO,B_r_NLO,E_r=E_r_LO_(E_r,I_r)\n",
    "nomitted=kmax-nLECs+1\n",
    "\n",
    "\n",
    "n=len(I_odd)\n",
    "cor1=[]\n",
    "for nla1 in range(nla,n-ll,1):\n",
    "    print(nla1)\n",
    "\n",
    "    samples,autocorrelation=np.load('samples_'+odd+'_N'+str(nLECs-1)+'LO_error_'+str(nomitted)+'_levles_'+str(nlb)+'_'+str(n-nla1)+'.npy',allow_pickle=True)\n",
    "    tau = autocorrelation\n",
    "    burnin = int(2 * np.max(tau))\n",
    "    thin = int(0.5 * np.min(tau))\n",
    "\n",
    "    flat_samples=samples[burnin::thin, :, :]\n",
    "    flat_samples = [item for sublist in flat_samples for item in sublist]\n",
    "    z=np.array(flat_samples).T\n",
    "    cor=abs(np.corrcoef(z))\n",
    "    cor1.append(cor[LEC])\n",
    "    \n",
    "np.save('cor_'+str(labels[LEC])+'_'+odd+'_N'+str(nLECs-1)+'LO_error_'+str(nomitted)+'_levles_'+str(nlb)+'_'+str(n-nla),cor1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nuclei=[r'$^{169}$Er',r'$^{167}$Er',r'$^{169}$Tm',r'$^{167}$Tm',r'$^{235}$U',r'$^{239}$Pu',r'$^{183}$W',r'$^{99}$Tc']\n",
    "odd=nuclei[0]\n",
    "ll=4\n",
    "\n",
    "for LEC in [0]:\n",
    "    \n",
    "    if LEC >1: s=LEC+1\n",
    "    else: s=2\n",
    "        \n",
    "    for nLECs in range(5,6,1):\n",
    "\n",
    "        rotor,bandhead,sigma_E,Q_cutoff,c_bar_cutoff_odd,c_bar_cutoff_even,range_of_starting_guesses,m,nla,nlb,labels=nuclei_parm(odd)\n",
    "        E_rot,E_vib,E_sp,E_r,error_r_ex,I_r,E_odd,error_odd_ex,I_odd=experiment_levels(rotor,odd)\n",
    "        A,A_r_NLO,B_r_NLO,E_r=E_r_LO_(E_r,I_r)\n",
    "\n",
    "        n=len(I_odd)\n",
    "        for kmax in [10]:\n",
    "            y11=[]\n",
    "            for nlb in range(n-nla-6,-1,-1):\n",
    "\n",
    "                nomitted=kmax-nLECs+1\n",
    "                E_odd,error_odd_ex,I_odd=E_odd[nlb:n-nla],error_odd_ex[nlb:n-nla],I_odd[nlb:n-nla]\n",
    "                samples,autocorrelation=np.load('samples/samples_'+odd+'_N'+str(nLECs-1)+'LO_error_'+str(nomitted)+'_levles_'+str(nlb)+'_'+str(n-nla)+'.npy',allow_pickle=True)\n",
    "                tau = autocorrelation\n",
    "                burnin = int(2 * np.max(tau))\n",
    "                thin = int(0.5 * np.min(tau))\n",
    "\n",
    "                flat_samples=samples[burnin::thin, :, :]\n",
    "                flat_samples = [item for sublist in flat_samples for item in sublist]\n",
    "                z=np.array(flat_samples).T\n",
    "\n",
    "                y=z[LEC]\n",
    "                mcmc = np.percentile(y, [16, 50, 84])\n",
    "                y1= np.array([mcmc[1],np.diff(mcmc)[0],np.diff(mcmc)[1]])\n",
    "                y11.append((y1))\n",
    "                \n",
    "                if len(z[LEC]) < 50 * np.mean(autocorrelation):\n",
    "                    print(str(labels[LEC])+'_'+odd+'_N'+str(nLECs-1)+'LO_error_'+str(nomitted)+'_levles_'+str(nlb)+'_'+str(n-nla)+'_b')\n",
    "                    print(len(z[LEC])/autocorrelation[LEC])\n",
    "\n",
    "            \n",
    "        np.save('parameters for plots/'+str(labels[LEC])+'_'+odd+'_N'+str(nLECs-1)+'LO_error_'+str(nomitted)+'_levles_'+str(nlb)+'_'+str(n-nla)+'_b',y11)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
